# DPIC Take Home Assignment - CÃ©sar NÃºÃ±ez

This project presents a full data pipeline and analysis workflow for monitoring vocational training programs in Odisha, using ITI enrollments and citizen grievances.

## ğŸ“¦ Project Structure
```
dpic_takehome/ 
â”œâ”€â”€ air_flow_automation/
    â”œâ”€â”€ dpic_dag.py         # Airflow DAG script
    â””â”€â”€ README.md           # Logic of the workflow
â”œâ”€â”€ dashboard/
    â”œâ”€â”€ app.py              # Dashboard layout
    â””â”€â”€ figures.py          # 
â”œâ”€â”€ data_pipeline/          
    â”œâ”€â”€ cleaning.py         # Cleans the raw data
    â”œâ”€â”€ data_to_db.py       # Creates a db and inserts clean data into the db
    â”œâ”€â”€ fetch_data.py       # Fetches raw data from an URL
    â””â”€â”€ run_queries.py      # Runs the queries required for the dashboard
â”œâ”€â”€ sql/
    â”œâ”€â”€ queries.sql         # Contains the queries required for the dashboard
    â””â”€â”€ schema.sql          # Contains the SQL schema
â””â”€â”€ __main__.py             # Runs the whole project as a module
|
data/ 
â”œâ”€â”€ raw/                    # Raw input files  
â”œâ”€â”€ clean/                  # Cleaned datasets  
â””â”€â”€ dpic.db                 # SQLite database 
README.md                   
```

## **Part 1: Data Pipeline & Cleaning**

### Input Files:
- `iti_enrollments.csv`: District-level enrollment counts by year
- `grievances.json`: Citizen complaints 

### Process:
- Cleaning scripts standardize district names, handle missing data, and remove duplicates.
- Data is loaded into an SQLite DB (`data/dpic.db`) using `data_pipeline/load_data.py`.

### SQL Schema:
Defined in `sql/schema.sql`, with:
- `iti_enrollments` table
- `grievances` table
- `districts` table
- `itis` table

### Queries:
Saved in `sql/queries.sql` and executed via `data_pipeline/run_queries.py`:
- Year-wise enrollment trends by gender
- Year-wise grievences trends by type of grievances
- Grievances per 1000 enrolled students by district
- Districts with high enrollments but low grievance submissions
- Types of grievances per district
- Enrollment by program and district

## **Part 2: Pipeline Automation**

This Apache Airflow DAG mimics the weekly automation for the take home assignment. It includes the following tasks in a sequence:
1. `fetch_raw_data`: Fetches the latest raw data from a GitHub repository.
2. `clean_data`: Runs the data cleaning functions.
3. `load_db_data`: Inserts cleaned data into the database.
4. `send_email_summary`: Emails a summary report from the weekly automation.

## **Part 3: Visualization & Insights**

### ğŸ“ Tool:
- [Plotly Dash] or [Streamlit] (see `dashboard/`)

### Features:
- Line/bar charts of district enrollments
- Grievance submission patterns
- Mismatch highlights: high enrollments vs low grievance rates

### ğŸ“ Insight Brief:
See `insight_brief.md` or `insight_brief.pdf` for a summary of 3 actionable insights derived from the data.


## ğŸ› ï¸ Setup Instructions

1. Clone the repo:
```bash
git clone https://github.com/your-username/dpic-takehome-assignment.git
cd dpic-takehome-assignment
```
2. Clone the repo:
```bash

```
3. Run the project as a module:
```
uv run -m dpic_takehome
```